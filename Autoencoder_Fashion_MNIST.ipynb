{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, we will see how we can use autoencoder as a classifier with fashion MNIST dataset.\n",
    "- Fashion MNIST dataset is a 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images, and the test set has 10,000 images.\n",
    "- It is a replacement for the original MNIST handwritten digits dataset for producing better results. The Fashion MNIST dataset consists of 10 different classes of fashion accessories like shirts, trousers, sandals, etc \n",
    "- The image dimensions, training and test splits are similar to the original MNIST dataset. \n",
    "- The dataset is freely available on this URL and can be loaded using both tensorflow and keras as a framework without having to download it on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what we want to do is built a convolutional autoencoder and use the encoder part of it combined with fully connected layers to recognize a new sample from the test set correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chhayc/anaconda3/envs/chhayc/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Loading the dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gzip\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Adadelta\n",
    "from keras.layers import Conv2D, Input, Dense, Flatten,Dropout, merge, Reshape, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from keras import backend as k\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way we read the data is as follows:\n",
    "- We open and read the gzip file as bytestream\n",
    "- We then convert the string stored in buffer using np.frombuffer() to numpy array of type float32.\n",
    "- Data is then reshaped into a 3-dimentional array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buffer = bytestream.read(28 * 28 * num_images)\n",
    "        data = np.frombuffer(buffer, dtype = np.uint8).astype(np.float32)\n",
    "        data = data.reshape(num_images, 28,28)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = extract_data('train-images-idx3-ubyte.gz' ,60000)\n",
    "test_data = extract_data('t10k-images-idx3-ubyte.gz',10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way we read the labels is the same as we read the data:\n",
    "- We define a function which opens the label file as a bytestream using bytestream.read() to which you pass the label dimension as 1 and the total number of images.\n",
    "- We then convert the string stored in the buffer to a numpy array of type int64.\n",
    "- We do not need to reshape the array since the variable labels will return a column vector of dimension 60,000 x 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buffer = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buffer, dtype = np.uint8).astype(np.uint64)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = extract_labels('train-labels-idx1-ubyte.gz', 60000)\n",
    "test_labels = extract_labels('t10k-labels-idx1-ubyte.gz',10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, 3, 0, 2, 7, 2, 5, 5], dtype=uint64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (images) shape: {shape} (60000, 28, 28)\n",
      "Test set (image) shape: {shape} (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# To see the dimension of images in the training set\n",
    "print(\"Training set (images) shape: {shape}\", format(train_data.shape))\n",
    "\n",
    "# To see the dimension of images in the test set\n",
    "print(\"Test set (image) shape: {shape}\", format(test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need training an testing labels for convolutional encoder as the task at hand is to reconstruct the images. However, we do need them for classification task and for data exploration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will now create a dictionary of class names with their corresponding class labels:\n",
    "label_dict = {\n",
    "    0: 'A',\n",
    "    1: 'B',\n",
    "    2: 'C',\n",
    "    3: 'D',\n",
    "    4: 'E',\n",
    "    5: 'F',\n",
    "    6: 'G',\n",
    "    7: 'H',\n",
    "    8: 'I',\n",
    "    9: 'J' \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now look at few of the images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'(Label: E)')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8558def7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# display an image from the training data\n",
    "plt.subplot(121)\n",
    "curr_img = np.reshape(train_data[10], (28,28))\n",
    "curr_label = train_labels[10]\n",
    "plt.imshow(curr_img, cmap = 'gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_label]) + \")\")\n",
    "\n",
    "# display an image from the testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(test_data[10], (28,28))\n",
    "curr_label = test_labels[10]\n",
    "plt.imshow(curr_img, cmap= 'gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_label])+ \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These images are assigned class labels as 0 or A / 4 or E. This means all the alphabets having class of E will have the class label of 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do the preprocessing of the data before feeding it to the model as our images are gray scale images having pixel values ranging from 0 to 255 with dimension of 28 * 28.\n",
    "So we will convert each 28 * 28 image into a matrix of size 28 * 28 * 1 which can be fed to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape (60000, 28, 28, 1)\n",
      "Test data shape (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.reshape(-1, 28, 28, 1)\n",
    "test_data = test_data.reshape(-1, 28, 28, 1)\n",
    "print(\"Train data shape\", train_data.shape)\n",
    "print(\"Test data shape\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), dtype('float32'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the datatype of the numpy arrays\n",
    "train_data.dtype, test_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescaling the pixel values to 0-1 scale by rescaling with maximum pixel value of the training and testing data\n",
    "train_data = train_data / np.max(train_data)\n",
    "test_data = test_data / np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify the maximum value of the training and the testing data\n",
    "np.max(train_data), np.max(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now split the data into 80% training and 20% validation. This will help us to reduce the chances of overfitting\n",
    "# as you would be validating the model on the data it has not seen in the training.\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data, train_data, test_size = 0.2, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 28, 28, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 28, 28, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the data is ready to be fed to the network. \n",
    "batch_size = 128\n",
    "epochs = 200\n",
    "channel = 1\n",
    "x, y = 28, 28\n",
    "input_image = Input(shape = (x, y, channel))\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build encoder and a decoder using convolutional layers.\n",
    "Batch Normalization layer is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building an encoder\n",
    "def encoder(input_image):\n",
    "    # input dimension - 28 * 28 * 1\n",
    "    conv1 = Conv2D(32, (3,3), activation = 'relu', padding = 'same') (input_image)  # 28 *28 * 32\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3,3), activation = 'relu', padding = 'same') (conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size = (2,2))(conv1)  # 14 * 14 * 32\n",
    "    conv2 = Conv2D(64, (3,3), activation = 'relu', padding = 'same') (pool1) # 14 * 14 * 64\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3,3), activation = 'relu', padding = 'same') (conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size = (2,2)) (conv2) # 7 * 7 * 64\n",
    "    conv3 = Conv2D(128, (3,3), activation = 'relu', padding = 'same') (pool2) # 7 * 7 * 128\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3,3), activation = 'relu', padding = 'same') (conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv4 = Conv2D(256,(3,3), activation = 'relu', padding = 'same') (conv3) # 7 * 7 * 256\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(256, (3,3), activation = 'relu', padding = 'same') (conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    return conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a decoder\n",
    "def decoder(conv4):\n",
    "    conv5 = Conv2D(128, (3,3), activation = 'relu', padding = 'same') (conv4) # 7 * 7 * 128\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(128, (3,3), activation = 'relu', padding = 'same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv6 = Conv2D(64, (3,3), activation= 'relu', padding ='same') (conv5)# 7 * 7 * 64\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(64, (3,3), activation= 'relu', padding = 'same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    up1 = UpSampling2D((2,2)) (conv6)  # 14 * 14 * 64\n",
    "    conv7 = Conv2D(32, (3,3), activation = 'relu', padding = 'same') (up1)# 14 * 14 * 32\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(32, (3,3), activation ='relu', padding = 'same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    up2 = UpSampling2D((2,2))(conv7) # 28 * 28 * 32\n",
    "    decoded = Conv2D(1,(3, 3),  activation = 'sigmoid', padding ='same') (up2) # 28 * 28 * 1\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model using RMSProp optimizer (helps in reducing overfitting by \n",
    "# changing learning rate while the model is training) and specifying the loss as mean squared loss\n",
    "autoencoder = Model(input_image, decoder(encoder(input_image)))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 7, 7, 128)         295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 7, 7, 64)          73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 1,758,657\n",
      "Trainable params: 1,755,841\n",
      "Non-trainable params: 2,816\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let us see the autoencoder summary\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/200\n",
      "48000/48000 [==============================] - 12s 257us/step - loss: 0.0270 - val_loss: 0.0203\n",
      "Epoch 2/200\n",
      "48000/48000 [==============================] - 10s 200us/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 3/200\n",
      "48000/48000 [==============================] - 10s 201us/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 4/200\n",
      "48000/48000 [==============================] - 10s 201us/step - loss: 0.0080 - val_loss: 0.0089\n",
      "Epoch 5/200\n",
      "48000/48000 [==============================] - 10s 200us/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 6/200\n",
      "48000/48000 [==============================] - 10s 201us/step - loss: 0.0060 - val_loss: 0.0064\n",
      "Epoch 7/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0052 - val_loss: 0.0076\n",
      "Epoch 8/200\n",
      "48000/48000 [==============================] - 10s 202us/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 9/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0045 - val_loss: 0.0061\n",
      "Epoch 10/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0041 - val_loss: 0.0069\n",
      "Epoch 11/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0039 - val_loss: 0.0083\n",
      "Epoch 12/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 13/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 14/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 15/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 16/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 17/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 18/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 19/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 20/200\n",
      "48000/48000 [==============================] - 10s 202us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 21/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 22/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 23/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 24/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 25/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 26/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 27/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 28/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 29/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 30/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 31/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 32/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 33/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 34/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 35/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 36/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 37/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 38/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 39/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 40/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 41/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 42/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 43/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 44/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 45/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 46/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 47/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 48/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 49/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 50/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 51/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 52/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 53/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 54/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 55/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 56/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 57/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 58/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 59/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 60/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 61/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 62/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 63/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 64/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 65/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 66/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 67/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 68/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 69/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 70/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 71/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 72/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 73/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 74/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 75/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0013 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 77/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 78/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 79/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 80/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 81/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 82/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 83/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 84/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 85/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 86/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 87/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 88/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 89/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 90/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 91/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 92/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 93/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 94/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 95/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 96/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 97/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 98/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 99/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 100/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 101/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 102/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 103/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 104/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 105/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 106/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 107/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 108/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 109/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 110/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 111/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 112/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 113/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 114/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 115/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 116/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 117/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 118/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 119/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 120/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 121/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 122/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 123/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 9.9526e-04 - val_loss: 0.0013\n",
      "Epoch 124/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.8864e-04 - val_loss: 0.0011\n",
      "Epoch 125/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.9224e-04 - val_loss: 0.0012\n",
      "Epoch 126/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.9101e-04 - val_loss: 0.0011\n",
      "Epoch 127/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.8464e-04 - val_loss: 0.0011\n",
      "Epoch 128/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 9.7299e-04 - val_loss: 0.0012\n",
      "Epoch 129/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 9.7548e-04 - val_loss: 0.0011\n",
      "Epoch 130/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 9.6940e-04 - val_loss: 0.0011\n",
      "Epoch 131/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 9.5951e-04 - val_loss: 0.0012\n",
      "Epoch 132/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 9.6218e-04 - val_loss: 0.0011\n",
      "Epoch 133/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 9.5824e-04 - val_loss: 0.0011\n",
      "Epoch 134/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 9.5460e-04 - val_loss: 0.0011\n",
      "Epoch 135/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.4670e-04 - val_loss: 0.0011\n",
      "Epoch 136/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 9.5131e-04 - val_loss: 0.0011\n",
      "Epoch 137/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.4409e-04 - val_loss: 0.0011\n",
      "Epoch 138/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.3989e-04 - val_loss: 0.0011\n",
      "Epoch 139/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 9.3604e-04 - val_loss: 0.0011\n",
      "Epoch 140/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.3760e-04 - val_loss: 0.0012\n",
      "Epoch 141/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.2972e-04 - val_loss: 0.0011\n",
      "Epoch 142/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.2859e-04 - val_loss: 0.0011\n",
      "Epoch 143/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.2579e-04 - val_loss: 0.0011\n",
      "Epoch 144/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.2181e-04 - val_loss: 0.0011\n",
      "Epoch 145/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.2095e-04 - val_loss: 0.0011\n",
      "Epoch 146/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.1431e-04 - val_loss: 0.0010\n",
      "Epoch 147/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.1790e-04 - val_loss: 0.0011\n",
      "Epoch 148/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.0914e-04 - val_loss: 0.0012\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.0550e-04 - val_loss: 0.0011\n",
      "Epoch 150/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 9.1026e-04 - val_loss: 0.0011\n",
      "Epoch 151/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 9.0270e-04 - val_loss: 0.0011\n",
      "Epoch 152/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 8.9546e-04 - val_loss: 0.0012\n",
      "Epoch 153/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.9899e-04 - val_loss: 0.0011\n",
      "Epoch 154/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.9249e-04 - val_loss: 0.0011\n",
      "Epoch 155/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.8935e-04 - val_loss: 0.0010\n",
      "Epoch 156/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.9183e-04 - val_loss: 0.0010\n",
      "Epoch 157/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.8655e-04 - val_loss: 9.9375e-04\n",
      "Epoch 158/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.7747e-04 - val_loss: 0.0010\n",
      "Epoch 159/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.8158e-04 - val_loss: 0.0011\n",
      "Epoch 160/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.7807e-04 - val_loss: 0.0010\n",
      "Epoch 161/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.7680e-04 - val_loss: 0.0010\n",
      "Epoch 162/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.6823e-04 - val_loss: 0.0011\n",
      "Epoch 163/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.6884e-04 - val_loss: 0.0010\n",
      "Epoch 164/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.5815e-04 - val_loss: 0.0010\n",
      "Epoch 165/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.5833e-04 - val_loss: 0.0010\n",
      "Epoch 166/200\n",
      "48000/48000 [==============================] - 10s 202us/step - loss: 8.6677e-04 - val_loss: 0.0011\n",
      "Epoch 167/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.6425e-04 - val_loss: 0.0011\n",
      "Epoch 168/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.5831e-04 - val_loss: 0.0011\n",
      "Epoch 169/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.5617e-04 - val_loss: 0.0011\n",
      "Epoch 170/200\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 8.5173e-04 - val_loss: 9.9452e-04\n",
      "Epoch 171/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.5209e-04 - val_loss: 0.0010\n",
      "Epoch 172/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.4898e-04 - val_loss: 0.0011\n",
      "Epoch 173/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.4201e-04 - val_loss: 0.0011\n",
      "Epoch 174/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.4518e-04 - val_loss: 0.0010\n",
      "Epoch 175/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.4755e-04 - val_loss: 0.0011\n",
      "Epoch 176/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.3737e-04 - val_loss: 0.0011\n",
      "Epoch 177/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.3311e-04 - val_loss: 0.0010\n",
      "Epoch 178/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.3870e-04 - val_loss: 0.0011\n",
      "Epoch 179/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.3328e-04 - val_loss: 0.0010\n",
      "Epoch 180/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.3385e-04 - val_loss: 0.0011\n",
      "Epoch 181/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.3475e-04 - val_loss: 0.0010\n",
      "Epoch 182/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.2865e-04 - val_loss: 0.0011\n",
      "Epoch 183/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.2886e-04 - val_loss: 0.0011\n",
      "Epoch 184/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.2159e-04 - val_loss: 0.0010\n",
      "Epoch 185/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.2494e-04 - val_loss: 0.0011\n",
      "Epoch 186/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.2118e-04 - val_loss: 0.0010\n",
      "Epoch 187/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.1950e-04 - val_loss: 9.8426e-04\n",
      "Epoch 188/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.2166e-04 - val_loss: 9.8741e-04\n",
      "Epoch 189/200\n",
      "48000/48000 [==============================] - 10s 202us/step - loss: 8.1405e-04 - val_loss: 0.0010\n",
      "Epoch 190/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.1347e-04 - val_loss: 9.8032e-04\n",
      "Epoch 191/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.0964e-04 - val_loss: 0.0011\n",
      "Epoch 192/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.1106e-04 - val_loss: 0.0011\n",
      "Epoch 193/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.0848e-04 - val_loss: 0.0011\n",
      "Epoch 194/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.0513e-04 - val_loss: 9.9635e-04\n",
      "Epoch 195/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.0401e-04 - val_loss: 0.0010\n",
      "Epoch 196/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.0518e-04 - val_loss: 0.0011\n",
      "Epoch 197/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 8.0324e-04 - val_loss: 9.7908e-04\n",
      "Epoch 198/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 7.9818e-04 - val_loss: 9.9786e-04\n",
      "Epoch 199/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 7.9632e-04 - val_loss: 0.0010\n",
      "Epoch 200/200\n",
      "48000/48000 [==============================] - 10s 203us/step - loss: 7.9219e-04 - val_loss: 0.0011\n"
     ]
    }
   ],
   "source": [
    "# we will now train the autoencoder for 200 epochs using keras fit function\n",
    "# We are going to save the history to plot accuracy and loss curves to help in analyzing the model performance.\n",
    "autoencoder_train = autoencoder.fit(X_train, y_train, batch_size = batch_size, epochs= epochs,\n",
    "                                   verbose =1, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
